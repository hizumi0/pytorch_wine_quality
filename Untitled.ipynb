{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader , TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/GenseiYoshimura/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/GenseiYoshimura/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0            1         0       3   0  22.0      1      0   7.2500        S\n",
       "1            2         1       1   1  38.0      1      0  71.2833        C\n",
       "2            3         1       3   1  26.0      0      0   7.9250        S\n",
       "3            4         1       1   1  35.0      1      0  53.1000        S\n",
       "4            5         0       3   0  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/train.csv\").drop('Ticket',axis=1).drop('Cabin',axis=1).drop('Name',axis=1)\n",
    "data[\"Sex\"][data[\"Sex\"] == \"male\"] = 0\n",
    "data[\"Sex\"][data[\"Sex\"] == \"female\"] = 1\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.361582</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.019697</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.361582    0.523008   \n",
       "std     257.353842    0.486592    0.836071   13.019697    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Age\"] = data[\"Age\"].fillna(data[\"Age\"].median())\n",
    "data[\"Embarked\"] = data[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  \\\n",
       "0          1.0       0.0     3.0  0.0  22.0    1.0    0.0   7.2500   \n",
       "1          2.0       1.0     1.0  1.0  38.0    1.0    0.0  71.2833   \n",
       "2          3.0       1.0     3.0  1.0  26.0    0.0    0.0   7.9250   \n",
       "3          4.0       1.0     1.0  1.0  35.0    1.0    0.0  53.1000   \n",
       "4          5.0       0.0     3.0  0.0  35.0    0.0    0.0   8.0500   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         0.0         0.0         1.0  \n",
       "1         1.0         0.0         0.0  \n",
       "2         0.0         0.0         1.0  \n",
       "3         0.0         0.0         1.0  \n",
       "4         0.0         0.0         1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_columns = ['Embarked']\n",
    "\n",
    "dummy = pd.get_dummies(data[dummy_columns])\n",
    "data = pd.concat([data, dummy], axis=1).drop('Embarked',axis=1).astype(float)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_feature = data.loc[:, 'Pclass':'Embarked_S'].values\n",
    "data_target = data.loc[:, 'Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(data_feature)\n",
    "data_feature = scaler.transform(data_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_feature = data_feature[:700]\n",
    "data_train_target = data_target[:700]\n",
    "\n",
    "data_test_feature = data_feature[700:]\n",
    "data_test_target = data_target[700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_COLUMNS = len(data_feature[0])\n",
    "LAYER = 20\n",
    "hidden_layer = 10\n",
    "OUTPUT_SIZE=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    hidden_layer = x[0]\n",
    "    learning_rate = x[1]\n",
    "    model = Net(hidden_layer)\n",
    "    train_X = torch.from_numpy(data_train_feature).float()\n",
    "    train_Y = torch.from_numpy(data_train_target).long()\n",
    "    test_X = torch.from_numpy(data_test_feature).float()\n",
    "\n",
    "    train = TensorDataset(train_X, train_Y)\n",
    "    train_loader = DataLoader(train, batch_size=16, shuffle=True)\n",
    "    TrainingNN(model,train_loader,learning_rate)\n",
    "    \n",
    "    predicted = model(test_X).data[:,1]\n",
    "    \n",
    "    return -1 * sum((predicted.numpy() > 0.5).astype(int) == data_test_target) / len(data_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaces = [\n",
    "    (10,20, 30,40,50,60,70,80,90,100,110),\n",
    "    (0.001,0.01,0.1)\n",
    "]\n",
    "spaces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/GenseiYoshimura/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n",
      "/Users/GenseiYoshimura/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 tensor(23.0544)\n",
      "100 tensor(23.0127)\n",
      "150 tensor(23.0127)\n",
      "200 tensor(22.9918)\n",
      "250 tensor(23.0543)\n",
      "300 tensor(22.9710)\n",
      "50 tensor(30.8460)\n",
      "100 tensor(30.8252)\n",
      "150 tensor(30.7835)\n",
      "200 tensor(30.8252)\n",
      "250 tensor(30.8043)\n",
      "300 tensor(30.8252)\n",
      "50 tensor(21.2593)\n",
      "100 tensor(20.5136)\n",
      "150 tensor(20.1696)\n",
      "200 tensor(20.1249)\n",
      "250 tensor(19.9486)\n",
      "300 tensor(19.8109)\n",
      "50 tensor(21.5583)\n",
      "100 tensor(20.9612)\n",
      "150 tensor(20.9354)\n",
      "200 tensor(20.7844)\n",
      "250 tensor(20.4699)\n",
      "300 tensor(20.4553)\n",
      "50 tensor(22.2002)\n",
      "100 tensor(23.2210)\n",
      "150 tensor(23.2002)\n",
      "200 tensor(23.1793)\n",
      "250 tensor(23.2210)\n",
      "300 tensor(23.2002)\n",
      "50 tensor(21.5188)\n",
      "100 tensor(20.9121)\n",
      "150 tensor(20.7060)\n",
      "200 tensor(20.8696)\n",
      "250 tensor(20.9802)\n",
      "300 tensor(21.4285)\n",
      "50 tensor(21.5414)\n",
      "100 tensor(21.1045)\n",
      "150 tensor(20.8930)\n",
      "200 tensor(20.7370)\n",
      "250 tensor(20.2776)\n",
      "300 tensor(20.1000)\n",
      "50 tensor(21.4426)\n",
      "100 tensor(25.4293)\n",
      "150 tensor(25.4085)\n",
      "200 tensor(25.3877)\n",
      "250 tensor(25.4085)\n",
      "300 tensor(25.4502)\n",
      "50 tensor(40.7419)\n",
      "100 tensor(40.8043)\n",
      "150 tensor(40.7627)\n",
      "200 tensor(40.7627)\n",
      "250 tensor(40.8044)\n",
      "300 tensor(40.8252)\n",
      "50 tensor(21.4213)\n",
      "100 tensor(20.8111)\n",
      "150 tensor(20.5072)\n",
      "200 tensor(20.2845)\n",
      "250 tensor(20.1468)\n",
      "300 tensor(20.1782)\n"
     ]
    }
   ],
   "source": [
    "from skopt import gp_minimize\n",
    "res = gp_minimize(\n",
    "    f, spaces,\n",
    "    acq_func=\"EI\",\n",
    "    n_calls=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fun',\n",
       " 'func_vals',\n",
       " 'models',\n",
       " 'random_state',\n",
       " 'space',\n",
       " 'specs',\n",
       " 'x',\n",
       " 'x_iters']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[80, 0.001]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.80628272, -0.62827225, -0.87434555, -0.84293194, -0.79057592,\n",
       "       -0.82722513, -0.81675393, -0.78534031, -0.37172775, -0.84293194])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.func_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[100, 0.01],\n",
       " [100, 0.1],\n",
       " [80, 0.001],\n",
       " [40, 0.001],\n",
       " [10, 0.1],\n",
       " [20, 0.01],\n",
       " [40, 0.001],\n",
       " [50, 0.01],\n",
       " [100, 0.1],\n",
       " [40, 0.001]]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.7892376681614349\n"
     ]
    }
   ],
   "source": [
    "#ロジスティック回帰\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_feature, data_target, random_state=0)\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "score = logreg.score(X_test, y_test)\n",
    "print('Test set score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 0.01]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/GenseiYoshimura/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/Users/GenseiYoshimura/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 tensor(15.4210)\n",
      "100 tensor(14.8195)\n",
      "150 tensor(14.2503)\n",
      "200 tensor(14.1245)\n",
      "250 tensor(14.1359)\n",
      "300 tensor(13.9508)\n",
      "50 tensor(14.8543)\n",
      "100 tensor(14.7359)\n",
      "150 tensor(14.5572)\n",
      "200 tensor(15.0328)\n",
      "250 tensor(14.4910)\n",
      "300 tensor(14.4058)\n",
      "50 tensor(14.4304)\n",
      "100 tensor(14.5217)\n",
      "150 tensor(14.1064)\n",
      "200 tensor(13.9470)\n",
      "250 tensor(13.9397)\n",
      "300 tensor(14.1283)\n",
      "50 tensor(14.4401)\n",
      "100 tensor(14.5224)\n",
      "150 tensor(14.0685)\n",
      "200 tensor(14.1193)\n",
      "250 tensor(13.8054)\n",
      "300 tensor(14.0843)\n",
      "50 tensor(14.7654)\n",
      "100 tensor(14.6150)\n",
      "150 tensor(14.3711)\n",
      "200 tensor(14.5978)\n",
      "250 tensor(14.2899)\n",
      "300 tensor(14.1856)\n",
      "50 tensor(14.4107)\n",
      "100 tensor(14.2340)\n",
      "150 tensor(14.1413)\n",
      "200 tensor(14.5187)\n",
      "250 tensor(14.4866)\n",
      "300 tensor(14.6337)\n",
      "50 tensor(17.5854)\n",
      "100 tensor(18.0229)\n",
      "150 tensor(17.5854)\n",
      "200 tensor(17.5854)\n",
      "250 tensor(17.5854)\n",
      "300 tensor(27.7103)\n",
      "50 tensor(21.2520)\n",
      "100 tensor(20.9812)\n",
      "150 tensor(20.9812)\n",
      "200 tensor(20.7104)\n",
      "250 tensor(20.7103)\n",
      "300 tensor(21.5229)\n",
      "50 tensor(15.5447)\n",
      "100 tensor(15.2731)\n",
      "150 tensor(15.2729)\n",
      "200 tensor(15.2729)\n",
      "250 tensor(15.8145)\n",
      "300 tensor(15.2729)\n",
      "50 tensor(14.5827)\n",
      "100 tensor(14.2997)\n",
      "150 tensor(14.0335)\n",
      "200 tensor(13.9702)\n",
      "250 tensor(14.0682)\n",
      "300 tensor(13.8478)\n",
      "50 tensor(14.8383)\n",
      "100 tensor(14.9976)\n",
      "150 tensor(14.7349)\n",
      "200 tensor(14.8460)\n",
      "250 tensor(14.2200)\n",
      "300 tensor(14.3913)\n",
      "50 tensor(14.4792)\n",
      "100 tensor(14.3321)\n",
      "150 tensor(14.2043)\n",
      "200 tensor(13.9244)\n",
      "250 tensor(13.8724)\n",
      "300 tensor(13.6134)\n",
      "50 tensor(14.1742)\n",
      "100 tensor(14.9644)\n",
      "150 tensor(15.2615)\n",
      "200 tensor(14.1940)\n",
      "250 tensor(14.5804)\n",
      "300 tensor(13.9685)\n",
      "50 tensor(14.9258)\n",
      "100 tensor(14.8362)\n",
      "150 tensor(14.5820)\n",
      "200 tensor(14.3858)\n",
      "250 tensor(14.4830)\n",
      "300 tensor(14.1756)\n",
      "50 tensor(14.6101)\n",
      "100 tensor(14.0780)\n",
      "150 tensor(14.0954)\n",
      "200 tensor(14.0588)\n",
      "250 tensor(14.2665)\n",
      "300 tensor(13.8198)\n",
      "50 tensor(20.5854)\n",
      "100 tensor(21.0229)\n",
      "150 tensor(21.0229)\n",
      "200 tensor(21.4604)\n",
      "250 tensor(20.5854)\n",
      "300 tensor(20.5854)\n",
      "50 tensor(21.5229)\n",
      "100 tensor(20.7104)\n",
      "150 tensor(20.7104)\n",
      "200 tensor(20.9812)\n",
      "250 tensor(20.9812)\n",
      "300 tensor(20.9812)\n",
      "50 tensor(15.2729)\n",
      "100 tensor(27.8145)\n",
      "150 tensor(27.8145)\n",
      "200 tensor(27.8145)\n",
      "250 tensor(28.0853)\n",
      "300 tensor(27.5437)\n",
      "50 tensor(14.9994)\n",
      "100 tensor(14.3587)\n",
      "150 tensor(14.1267)\n",
      "200 tensor(13.9946)\n",
      "250 tensor(14.0441)\n",
      "300 tensor(13.8996)\n",
      "50 tensor(14.7365)\n",
      "100 tensor(14.9353)\n",
      "150 tensor(14.7087)\n",
      "200 tensor(14.2655)\n",
      "250 tensor(14.2680)\n",
      "300 tensor(14.1455)\n",
      "50 tensor(14.0686)\n",
      "100 tensor(13.8900)\n",
      "150 tensor(13.8732)\n",
      "200 tensor(13.9997)\n",
      "250 tensor(13.9377)\n",
      "300 tensor(13.6363)\n",
      "50 tensor(14.2336)\n",
      "100 tensor(14.2464)\n",
      "150 tensor(15.6198)\n",
      "200 tensor(14.5822)\n",
      "250 tensor(13.7486)\n",
      "300 tensor(15.4705)\n",
      "50 tensor(15.4706)\n",
      "100 tensor(14.6064)\n",
      "150 tensor(14.8534)\n",
      "200 tensor(14.2641)\n",
      "250 tensor(14.4646)\n",
      "300 tensor(15.0454)\n",
      "50 tensor(13.9750)\n",
      "100 tensor(15.9481)\n",
      "150 tensor(13.7893)\n",
      "200 tensor(14.2044)\n",
      "250 tensor(14.3199)\n",
      "300 tensor(13.8598)\n",
      "50 tensor(21.0854)\n",
      "100 tensor(20.6479)\n",
      "150 tensor(20.6479)\n",
      "200 tensor(20.6479)\n",
      "250 tensor(21.0854)\n",
      "300 tensor(21.0854)\n",
      "50 tensor(21.2520)\n",
      "100 tensor(20.9812)\n",
      "150 tensor(21.5229)\n",
      "200 tensor(20.7104)\n",
      "250 tensor(21.2520)\n",
      "300 tensor(21.2520)\n",
      "50 tensor(28.0853)\n",
      "100 tensor(27.2728)\n",
      "150 tensor(27.5437)\n",
      "200 tensor(27.8145)\n",
      "250 tensor(27.8145)\n",
      "300 tensor(27.8145)\n",
      "50 tensor(14.3906)\n",
      "100 tensor(14.0748)\n",
      "150 tensor(13.9104)\n",
      "200 tensor(13.7392)\n",
      "250 tensor(13.7295)\n",
      "300 tensor(13.9053)\n",
      "50 tensor(14.9547)\n",
      "100 tensor(14.5934)\n",
      "150 tensor(14.5969)\n",
      "200 tensor(14.6170)\n",
      "250 tensor(14.0042)\n",
      "300 tensor(13.9568)\n",
      "50 tensor(14.2982)\n",
      "100 tensor(13.9874)\n",
      "150 tensor(14.1328)\n",
      "200 tensor(13.9209)\n",
      "250 tensor(13.6252)\n",
      "300 tensor(13.5776)\n",
      "50 tensor(14.3911)\n",
      "100 tensor(15.0198)\n",
      "150 tensor(18.4218)\n",
      "200 tensor(17.9276)\n",
      "250 tensor(15.5471)\n",
      "300 tensor(16.2403)\n",
      "50 tensor(14.9736)\n",
      "100 tensor(15.5228)\n",
      "150 tensor(14.7447)\n",
      "200 tensor(14.2346)\n",
      "250 tensor(14.2701)\n",
      "300 tensor(14.3065)\n",
      "50 tensor(14.2927)\n",
      "100 tensor(14.1609)\n",
      "150 tensor(15.6895)\n",
      "200 tensor(15.6895)\n",
      "250 tensor(15.1479)\n",
      "300 tensor(15.4187)\n",
      "50 tensor(21.0854)\n",
      "100 tensor(21.0854)\n",
      "150 tensor(21.0854)\n",
      "200 tensor(20.6479)\n",
      "250 tensor(20.6479)\n",
      "300 tensor(21.0854)\n",
      "50 tensor(20.7104)\n",
      "100 tensor(20.9812)\n",
      "150 tensor(20.7104)\n",
      "200 tensor(20.7104)\n",
      "250 tensor(21.2520)\n",
      "300 tensor(20.7104)\n",
      "50 tensor(21.2520)\n",
      "100 tensor(21.2520)\n",
      "150 tensor(20.7104)\n",
      "200 tensor(20.7104)\n",
      "250 tensor(21.2520)\n",
      "300 tensor(20.9812)\n",
      "50 tensor(14.2168)\n",
      "100 tensor(14.9579)\n",
      "150 tensor(13.9045)\n",
      "200 tensor(13.8553)\n",
      "250 tensor(13.2961)\n",
      "300 tensor(13.1003)\n",
      "50 tensor(14.7009)\n",
      "100 tensor(14.5422)\n",
      "150 tensor(14.2823)\n",
      "200 tensor(14.2350)\n",
      "250 tensor(14.3134)\n",
      "300 tensor(13.8193)\n",
      "50 tensor(14.6870)\n",
      "100 tensor(14.4591)\n",
      "150 tensor(14.2022)\n",
      "200 tensor(13.7136)\n",
      "250 tensor(13.6695)\n",
      "300 tensor(13.4856)\n",
      "50 tensor(14.4913)\n",
      "100 tensor(14.6473)\n",
      "150 tensor(13.6126)\n",
      "200 tensor(13.7392)\n",
      "250 tensor(14.4319)\n",
      "300 tensor(14.4588)\n",
      "50 tensor(15.1821)\n",
      "100 tensor(15.2512)\n",
      "150 tensor(14.5038)\n",
      "200 tensor(15.8210)\n",
      "250 tensor(14.7645)\n",
      "300 tensor(14.4964)\n",
      "50 tensor(27.8145)\n",
      "100 tensor(27.8145)\n",
      "150 tensor(28.0853)\n",
      "200 tensor(27.8145)\n",
      "250 tensor(27.5437)\n",
      "300 tensor(27.8145)\n",
      "50 tensor(21.0854)\n",
      "100 tensor(20.6479)\n",
      "150 tensor(20.6479)\n",
      "200 tensor(21.0854)\n",
      "250 tensor(21.0854)\n",
      "300 tensor(20.6479)\n",
      "50 tensor(20.9812)\n",
      "100 tensor(21.5229)\n",
      "150 tensor(20.9812)\n",
      "200 tensor(20.7104)\n",
      "250 tensor(21.2520)\n",
      "300 tensor(20.9812)\n",
      "50 tensor(21.2520)\n",
      "100 tensor(21.2520)\n",
      "150 tensor(20.7104)\n",
      "200 tensor(21.5229)\n",
      "250 tensor(20.9812)\n",
      "300 tensor(20.9812)\n",
      "50 tensor(14.1679)\n",
      "100 tensor(14.1827)\n",
      "150 tensor(14.0523)\n",
      "200 tensor(13.4448)\n",
      "250 tensor(13.3738)\n",
      "300 tensor(13.4038)\n",
      "50 tensor(14.7889)\n",
      "100 tensor(14.6804)\n",
      "150 tensor(14.7236)\n",
      "200 tensor(14.6654)\n",
      "250 tensor(14.2697)\n",
      "300 tensor(13.9765)\n",
      "50 tensor(14.8592)\n",
      "100 tensor(13.8851)\n",
      "150 tensor(13.6625)\n",
      "200 tensor(13.5794)\n",
      "250 tensor(13.7570)\n",
      "300 tensor(13.7987)\n",
      "50 tensor(15.3468)\n",
      "100 tensor(14.5152)\n",
      "150 tensor(16.6479)\n",
      "200 tensor(16.2104)\n",
      "250 tensor(16.2104)\n",
      "300 tensor(16.2104)\n",
      "50 tensor(15.3537)\n",
      "100 tensor(14.6871)\n",
      "150 tensor(15.5470)\n",
      "200 tensor(14.8817)\n",
      "250 tensor(16.5131)\n",
      "300 tensor(14.7863)\n",
      "50 tensor(14.7105)\n",
      "100 tensor(14.9812)\n",
      "150 tensor(14.7104)\n",
      "200 tensor(14.9812)\n",
      "250 tensor(14.9812)\n",
      "300 tensor(14.7104)\n",
      "50 tensor(20.6479)\n",
      "100 tensor(20.6479)\n",
      "150 tensor(21.5229)\n",
      "200 tensor(21.5229)\n",
      "250 tensor(21.5229)\n",
      "300 tensor(20.6479)\n",
      "50 tensor(21.5229)\n",
      "100 tensor(20.7104)\n",
      "150 tensor(20.7104)\n",
      "200 tensor(20.9812)\n",
      "250 tensor(21.2520)\n",
      "300 tensor(21.2520)\n",
      "50 tensor(28.0853)\n",
      "100 tensor(27.8145)\n",
      "150 tensor(27.5437)\n",
      "200 tensor(27.5437)\n",
      "250 tensor(28.0853)\n",
      "300 tensor(27.5437)\n",
      "50 tensor(14.3725)\n",
      "100 tensor(14.4038)\n",
      "150 tensor(13.9203)\n",
      "200 tensor(13.6632)\n",
      "250 tensor(13.1369)\n",
      "300 tensor(12.9064)\n",
      "50 tensor(14.7133)\n",
      "100 tensor(14.2071)\n",
      "150 tensor(13.8913)\n",
      "200 tensor(14.0785)\n",
      "250 tensor(13.6636)\n",
      "300 tensor(13.9988)\n",
      "50 tensor(14.1247)\n",
      "100 tensor(14.0251)\n",
      "150 tensor(13.8978)\n",
      "200 tensor(13.7943)\n",
      "250 tensor(13.5064)\n",
      "300 tensor(13.3909)\n",
      "50 tensor(17.1298)\n",
      "100 tensor(15.2104)\n",
      "150 tensor(15.6479)\n",
      "200 tensor(15.2104)\n",
      "250 tensor(15.6479)\n",
      "300 tensor(15.2104)\n",
      "50 tensor(15.9815)\n",
      "100 tensor(15.2937)\n",
      "150 tensor(15.0229)\n",
      "200 tensor(15.2937)\n",
      "250 tensor(15.0229)\n",
      "300 tensor(15.0229)\n",
      "50 tensor(14.6546)\n",
      "100 tensor(14.9187)\n",
      "150 tensor(14.6479)\n",
      "200 tensor(14.9187)\n",
      "250 tensor(14.9187)\n",
      "300 tensor(14.6479)\n",
      "50 tensor(20.6479)\n",
      "100 tensor(21.0854)\n",
      "150 tensor(21.0854)\n",
      "200 tensor(21.0854)\n",
      "250 tensor(21.0854)\n",
      "300 tensor(21.0854)\n",
      "50 tensor(28.0853)\n",
      "100 tensor(28.0853)\n",
      "150 tensor(28.0853)\n",
      "200 tensor(27.8145)\n",
      "250 tensor(27.5437)\n",
      "300 tensor(27.5437)\n",
      "50 tensor(21.2520)\n",
      "100 tensor(21.2520)\n",
      "150 tensor(20.9812)\n",
      "200 tensor(21.2520)\n",
      "250 tensor(21.2520)\n",
      "300 tensor(21.2520)\n",
      "50 tensor(21.6223)\n",
      "100 tensor(21.5213)\n",
      "150 tensor(20.9495)\n",
      "200 tensor(20.6827)\n",
      "250 tensor(20.6828)\n",
      "300 tensor(20.3158)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=skNN(hidden_layer=20, lr=0.01), fit_params=None, iid=True,\n",
       "       n_jobs=1,\n",
       "       param_grid={'hidden_layer': [10, 20, 30, 40, 50, 60, 70], 'lr': [0.001, 0.01, 0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\n",
    "        'hidden_layer': [10,20,30,40,50,60,70],\n",
    "        'lr': [0.001,0.01,0.1],\n",
    "    }\n",
    "grid_search = GridSearchCV(skNN(),\n",
    "            param_grid=params,  \n",
    "            cv=3,  \n",
    "    )\n",
    "grid_search.fit(data_train_feature, data_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class skNN(BaseEstimator,nn.Module,ClassifierMixin):\n",
    "    def __init__(self, hidden_layer=20,lr=0.01):\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.lr = lr\n",
    "        \n",
    "        super(skNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(INPUT_COLUMNS,self.hidden_layer)\n",
    "        self.fc2 = nn.Linear(self.hidden_layer,self.hidden_layer)\n",
    "        self.fc3 = nn.Linear(self.hidden_layer,self.hidden_layer)\n",
    "        self.fc4 = nn.Linear(self.hidden_layer,OUTPUT_SIZE)\n",
    "        self.outact = nn.Softmax()\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.parameters(),lr=self.lr)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return self.outact(x)    \n",
    "        \n",
    "    def fit(self, X, y=None, valid_X=None, valid_y=None):\n",
    "        tensorX = torch.from_numpy(X).float()\n",
    "        tensorY = torch.from_numpy(y).long()\n",
    "        train = TensorDataset(tensorX,tensorY)\n",
    "        train_loader = DataLoader(train, batch_size=16, shuffle=True)\n",
    "\n",
    "        for epoch in range(300):\n",
    "            total_loss = 0    \n",
    "            for train_x, train_y in train_loader:\n",
    "                train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self(train_x)\n",
    "                loss = self.criterion(output, train_y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                total_loss += loss.data[0]\n",
    "            \n",
    "            if (epoch+1) % 50 == 0:\n",
    "                print(epoch+1, total_loss)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        tensorX = torch.from_numpy(X).float()\n",
    "        test_X = Variable(tensorX)\n",
    "        return (self(test_X).data[:,1].numpy() > 0.5).astype(int)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        tensorX = torch.from_numpy(X).float()\n",
    "        test_X = Variable(tensorX)\n",
    "        return self(test_X).data[:,1].numpy()\n",
    "    \n",
    "    def score(self,X,y):\n",
    "        tensorX = torch.from_numpy(X).float()\n",
    "        test_X = Variable(tensorX)\n",
    "        return sum( (self(test_X).data[:,1].numpy() > 0.5).astype(int) == y )/ len(y)\n",
    "    \n",
    "    def get_params(self,deep=True):\n",
    "        return {'hidden_layer': self.hidden_layer, 'lr': self.lr}\n",
    "    \n",
    "    def set_params(self,**params):\n",
    "        for parameter, value in params.items():\n",
    "            setattr(self,parameter, value)\n",
    "        self.fc1 = nn.Linear(INPUT_COLUMNS,self.hidden_layer)\n",
    "        self.fc2 = nn.Linear(self.hidden_layer,self.hidden_layer)\n",
    "        self.fc3 = nn.Linear(self.hidden_layer,self.hidden_layer)\n",
    "        self.fc4 = nn.Linear(self.hidden_layer,OUTPUT_SIZE)\n",
    "        self.optimizer = optim.Adam(self.parameters(),lr=self.lr)\n",
    "        return self\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 20, 30, 40, 50, 60, 70]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['hidden_layer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=skNN(hidden_layer=30,lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_layer': 40, 'lr': 0.001}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/GenseiYoshimura/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84293193717277481"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(data_test_feature,data_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    hidden_layer = x[0]\n",
    "    lr = x[1]\n",
    "    model = skNN(hidden_layer,lr)\n",
    "    model.fit(data_train_feature,data_train_target)\n",
    "    \n",
    "    predicted = model.predict(data_test_feature)\n",
    "    \n",
    "    return -1 * sum(predicted == data_test_target) / len(data_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/GenseiYoshimura/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/Users/GenseiYoshimura/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 tensor(30.8043)\n",
      "100 tensor(30.8043)\n",
      "150 tensor(30.8460)\n",
      "200 tensor(30.7835)\n",
      "250 tensor(30.8668)\n",
      "300 tensor(30.7835)\n",
      "50 tensor(40.7210)\n",
      "100 tensor(40.7627)\n",
      "150 tensor(40.7627)\n",
      "200 tensor(40.7002)\n",
      "250 tensor(40.7835)\n",
      "300 tensor(40.7210)\n",
      "50 tensor(21.5010)\n",
      "100 tensor(21.7557)\n",
      "150 tensor(21.4281)\n",
      "200 tensor(20.9887)\n",
      "250 tensor(22.9213)\n",
      "300 tensor(22.9754)\n",
      "50 tensor(23.0753)\n",
      "100 tensor(22.9919)\n",
      "150 tensor(23.0335)\n",
      "200 tensor(23.0335)\n",
      "250 tensor(23.0127)\n",
      "300 tensor(22.9918)\n",
      "50 tensor(29.5963)\n",
      "100 tensor(29.5461)\n",
      "150 tensor(29.4619)\n",
      "200 tensor(29.4428)\n",
      "250 tensor(29.5081)\n",
      "300 tensor(29.7572)\n",
      "50 tensor(23.2002)\n",
      "100 tensor(23.1793)\n",
      "150 tensor(30.8043)\n",
      "200 tensor(30.8252)\n",
      "250 tensor(30.8460)\n",
      "300 tensor(30.7835)\n",
      "50 tensor(27.6896)\n",
      "100 tensor(20.9980)\n",
      "150 tensor(20.9625)\n",
      "200 tensor(23.4067)\n",
      "250 tensor(22.5335)\n",
      "300 tensor(22.5960)\n",
      "50 tensor(30.7418)\n",
      "100 tensor(30.7418)\n",
      "150 tensor(30.8043)\n",
      "200 tensor(30.8252)\n",
      "250 tensor(30.8252)\n",
      "300 tensor(30.7835)\n",
      "50 tensor(21.3202)\n",
      "100 tensor(21.1686)\n",
      "150 tensor(20.8831)\n",
      "200 tensor(20.9131)\n",
      "250 tensor(20.8293)\n",
      "300 tensor(20.6556)\n",
      "50 tensor(30.8252)\n",
      "100 tensor(30.8460)\n",
      "150 tensor(30.8668)\n",
      "200 tensor(30.7835)\n",
      "250 tensor(30.8877)\n",
      "300 tensor(30.8043)\n"
     ]
    }
   ],
   "source": [
    "from skopt import gp_minimize\n",
    "res = gp_minimize(\n",
    "    f, spaces,\n",
    "    acq_func=\"EI\",\n",
    "    n_calls=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 0.01]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fun',\n",
       " 'func_vals',\n",
       " 'models',\n",
       " 'random_state',\n",
       " 'space',\n",
       " 'specs',\n",
       " 'x',\n",
       " 'x_iters']"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
